{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg is accessible\n",
      "Final Transcription: security so it doesnt feel very secure to me as a farmer to hear that in my family and i have been farming here since 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 397/397 [05:51<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Audio to text\n",
    "\n",
    "import os\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import whisper\n",
    "import subprocess\n",
    "import string\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\bin\"\n",
    "\n",
    "def check_ffmpeg():\n",
    "    try:\n",
    "        cmd = [\"ffmpeg\", \"-version\"]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"ffmpeg is accessible\")\n",
    "        else:\n",
    "            print(\"ffmpeg is not accessible\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ffmpeg not found\")\n",
    "\n",
    "check_ffmpeg()\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    audio = whisper.load_audio(file_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    _, probs = model.detect_language(mel)\n",
    "    \n",
    "    options = whisper.DecodingOptions(fp16=False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    transcription = result.text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    return transcription\n",
    "\n",
    "flac_file_path = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00002.flac'\n",
    "\n",
    "if os.path.isfile(flac_file_path):\n",
    "    transcription = transcribe_audio(flac_file_path)\n",
    "    print(f\"Final Transcription: {transcription}\")\n",
    "else:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "\n",
    "\n",
    "wav_directory = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel'\n",
    "\n",
    "transcriptions = []\n",
    "for filename in tqdm(os.listdir(wav_directory), desc=\"Processing files\"):\n",
    "    if filename.endswith(\".flac\"):\n",
    "        file_path = os.path.join(wav_directory, filename)\n",
    "        transcription = transcribe_audio(file_path)\n",
    "        transcriptions.append(transcription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to txt\n",
    "\n",
    "output_file_path = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\transcriptions_VitsModel.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    for transcription in transcriptions:\n",
    "        f.write(transcription + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt to List\n",
    "\n",
    "output_file_path = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\transcriptions_VitsModel.txt'\n",
    "with open(output_file_path, 'r') as f:\n",
    "    transcriptions_from_file = [line.strip() for line in f]\n",
    "\n",
    "transcriptions_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"clean.json\")\n",
    "\n",
    "textInput = [] \n",
    "audioPathInput = [] \n",
    "\n",
    "for data in dataset['train']['training_data']:\n",
    "    textInput.extend(data['label'])\n",
    "    audioPathInput.extend(data['name'])\n",
    "\n",
    "printInputArrays = False\n",
    "\n",
    "if printInputArrays:\n",
    "    for i in range(len(textInput)):\n",
    "        print(textInput[i])\n",
    "\n",
    "    for i in range(len(audioPathInput)):\n",
    "        print(audioPathInput[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input arrays are not of the same length.\n",
      "textInput: 336 transcriptions_from_file: 397\n"
     ]
    }
   ],
   "source": [
    "# Calculate the WER between two texts\n",
    "\n",
    "# Objective Evaluation\n",
    "# Word Error Rate (WER):\n",
    "\n",
    "# Transcribe the generated audio back to text using an automatic speech recognition (ASR) system.\n",
    "# Compare the transcribed text with the original text to calculate the WER. The model with the lower WER is better.\n",
    "\n",
    "from jiwer import wer\n",
    "\n",
    "if len(textInput)==len(transcriptions_from_file):\n",
    "    original_texts = textInput\n",
    "    transcribed_text_model1 = transcriptions_from_file\n",
    "    transcribed_text_model2 = []\n",
    "\n",
    "    wer_list_model1 = [wer(original, transcribed) for original, transcribed in zip(original_texts, transcribed_text_model1)] if transcribed_text_model1 else []\n",
    "    wer_list_model2 = [wer(original, transcribed) for original, transcribed in zip(original_texts, transcribed_text_model2)] if transcribed_text_model2 else []\n",
    "\n",
    "    average_wer_model1 = sum(wer_list_model1) / len(wer_list_model1) if wer_list_model1 else float('inf')\n",
    "    average_wer_model2 = sum(wer_list_model2) / len(wer_list_model2) if wer_list_model2 else float('inf')\n",
    "\n",
    "    print(f\"Average WER Model 1: {average_wer_model1}\")\n",
    "    print(f\"Average WER Model 2: {average_wer_model2}\")\n",
    "else:\n",
    "    print(\"Input arrays are not of the same length.\")\n",
    "    print(f\"textInput: {len(textInput)} transcriptions_from_file: {len(transcriptions_from_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptual Evaluation of Speech Quality (PESQ):\n",
    "\n",
    "# Use PESQ to measure the quality of the speech signals. PESQ compares the generated audio to a reference audio signal and gives a quality score.\n",
    "# Libraries like pypesq can be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "CouldntDecodeError",
     "evalue": "Decoding failed. ffmpeg returned error code: 3199971767\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 2024-05-15-git-7b47099bc0-full_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\r\n  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      59. 17.100 / 59. 17.100\r\n  libavcodec     61.  5.103 / 61.  5.103\r\n  libavformat    61.  3.103 / 61.  3.103\r\n  libavdevice    61.  2.100 / 61.  2.100\r\n  libavfilter    10.  2.101 / 10.  2.101\r\n  libswscale      8.  2.100 /  8.  2.100\r\n  libswresample   5.  2.100 /  5.  2.100\r\n  libpostproc    58.  2.100 / 58.  2.100\r\n[flac @ 0000028c0bff8940] Could not find codec parameters for stream 0 (Audio: flac, 0 channels): unspecified sample format\r\nConsider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options\r\nInput #0, flac, from 'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac':\r\n  Duration: N/A, bitrate: N/A\r\n  Stream #0:0: Audio: flac, 0 channels\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (flac (native) -> pcm_s32le (native))\r\nPress [q] to stop, [?] for help\r\nCannot determine format of input 0:0 after EOF\r\n[af#0:0 @ 0000028c0c013f00] Task finished with error code: -1094995529 (Invalid data found when processing input)\r\n[af#0:0 @ 0000028c0c013f00] Terminating thread with return code -1094995529 (Invalid data found when processing input)\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Could not open encoder before EOF\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Task finished with error code: -22 (Invalid argument)\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Terminating thread with return code -22 (Invalid argument)\r\n[out#0/wav @ 0000028c0c011f00] Nothing was written into output file, because at least one of its streams received no packets.\r\nsize=       0KiB time=N/A bitrate=N/A speed=N/A    \r\nConversion failed!\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCouldntDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m gen_wav_path_model2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCodeProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUniversity\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3.2_VU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdeep learning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgmmGroup\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maudioResults\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVitsModel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     26\u001b[0m convert_flac_to_wav(ref_flac_path, ref_wav_path)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mconvert_flac_to_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_flac_path_model1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_wav_path_model1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m convert_flac_to_wav(gen_flac_path_model2, gen_wav_path_model2)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Read WAV files\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[117], line 11\u001b[0m, in \u001b[0;36mconvert_flac_to_wav\u001b[1;34m(flac_file_path, wav_file_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_flac_to_wav\u001b[39m(flac_file_path, wav_file_path):\n\u001b[1;32m---> 11\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflac_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     audio\u001b[38;5;241m.\u001b[39mexport(wav_file_path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dauma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydub\\audio_segment.py:773\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close_file:\n\u001b[0;32m    772\u001b[0m         file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 773\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CouldntDecodeError(\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoding failed. ffmpeg returned error code: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutput from ffmpeg/avlib:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    775\u001b[0m             p\u001b[38;5;241m.\u001b[39mreturncode, p_err\u001b[38;5;241m.\u001b[39mdecode(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) ))\n\u001b[0;32m    777\u001b[0m p_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(p_out)\n\u001b[0;32m    778\u001b[0m fix_wav_headers(p_out)\n",
      "\u001b[1;31mCouldntDecodeError\u001b[0m: Decoding failed. ffmpeg returned error code: 3199971767\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 2024-05-15-git-7b47099bc0-full_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\r\n  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      59. 17.100 / 59. 17.100\r\n  libavcodec     61.  5.103 / 61.  5.103\r\n  libavformat    61.  3.103 / 61.  3.103\r\n  libavdevice    61.  2.100 / 61.  2.100\r\n  libavfilter    10.  2.101 / 10.  2.101\r\n  libswscale      8.  2.100 /  8.  2.100\r\n  libswresample   5.  2.100 /  5.  2.100\r\n  libpostproc    58.  2.100 / 58.  2.100\r\n[flac @ 0000028c0bff8940] Could not find codec parameters for stream 0 (Audio: flac, 0 channels): unspecified sample format\r\nConsider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options\r\nInput #0, flac, from 'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac':\r\n  Duration: N/A, bitrate: N/A\r\n  Stream #0:0: Audio: flac, 0 channels\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (flac (native) -> pcm_s32le (native))\r\nPress [q] to stop, [?] for help\r\nCannot determine format of input 0:0 after EOF\r\n[af#0:0 @ 0000028c0c013f00] Task finished with error code: -1094995529 (Invalid data found when processing input)\r\n[af#0:0 @ 0000028c0c013f00] Terminating thread with return code -1094995529 (Invalid data found when processing input)\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Could not open encoder before EOF\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Task finished with error code: -22 (Invalid argument)\r\n[aost#0:0/pcm_s32le @ 0000028c0c012f00] Terminating thread with return code -22 (Invalid argument)\r\n[out#0/wav @ 0000028c0c011f00] Nothing was written into output file, because at least one of its streams received no packets.\r\nsize=       0KiB time=N/A bitrate=N/A speed=N/A    \r\nConversion failed!\r\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pypesq import pesq\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from pypesq import pesq\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "\n",
    "def convert_flac_to_wav(flac_file_path, wav_file_path):\n",
    "    audio = AudioSegment.from_file(flac_file_path, format=\"flac\")\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "\n",
    "# File paths\n",
    "ref_flac_path = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\data\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac'\n",
    "gen_flac_path_model1 = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac'\n",
    "gen_flac_path_model2 = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.flac'\n",
    "\n",
    "\n",
    "# File paths\n",
    "ref_wav_path = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\data\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.wav'\n",
    "gen_wav_path_model1 = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.wav'\n",
    "gen_wav_path_model2 = r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.wav'\n",
    "\n",
    "\n",
    "convert_flac_to_wav(ref_flac_path, ref_wav_path)\n",
    "convert_flac_to_wav(gen_flac_path_model1, gen_wav_path_model1)\n",
    "convert_flac_to_wav(gen_flac_path_model2, gen_wav_path_model2)\n",
    "\n",
    "# Read WAV files\n",
    "rate, ref_audio = wavfile.read(ref_wav_path)\n",
    "rate, gen_audio_model1 = wavfile.read(gen_wav_path_model1)\n",
    "rate, gen_audio_model2 = wavfile.read(gen_wav_path_model2)\n",
    "\n",
    "# Compute PESQ scores\n",
    "pesq_score_model1 = pesq(rate, ref_audio, gen_audio_model1, 'wb')\n",
    "pesq_score_model2 = pesq(rate, ref_audio, gen_audio_model2, 'wb')\n",
    "\n",
    "print(f\"PESQ Score Model 1: {pesq_score_model1}\")\n",
    "print(f\"PESQ Score Model 2: {pesq_score_model2}\")\n",
    "\n",
    "# Clean up temporary WAV files if needed\n",
    "os.remove(ref_wav_path)\n",
    "os.remove(gen_wav_path_model1)\n",
    "os.remove(gen_wav_path_model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format b'fLaC' not understood. Only 'RIFF' and 'RIFX' supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypesq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pesq\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wavfile\n\u001b[1;32m----> 4\u001b[0m rate, ref_audio \u001b[38;5;241m=\u001b[39m \u001b[43mwavfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCodeProjects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUniversity\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m3.2_VU\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdeep learning\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgmmGroup\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m rate, gen_audio_model1 \u001b[38;5;241m=\u001b[39m wavfile\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCodeProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUniversity\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3.2_VU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdeep learning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgmmGroup\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maudioResults\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVitsModel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m rate, gen_audio_model2 \u001b[38;5;241m=\u001b[39m wavfile\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCodeProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUniversity\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3.2_VU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdeep learning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgmmGroup\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maudioResults\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVitsModel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.flac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dauma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\io\\wavfile.py:650\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m \u001b[43m_read_riff_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     fmt_chunk_received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    652\u001b[0m     data_chunk_received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dauma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\io\\wavfile.py:521\u001b[0m, in \u001b[0;36m_read_riff_chunk\u001b[1;34m(fid)\u001b[0m\n\u001b[0;32m    518\u001b[0m     fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>I\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;66;03m# There are also .wav files with \"FFIR\" or \"XFIR\" signatures?\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(str1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not understood. Only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# Size of entire file\u001b[39;00m\n\u001b[0;32m    525\u001b[0m file_size \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(fmt, fid\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: File format b'fLaC' not understood. Only 'RIFF' and 'RIFX' supported."
     ]
    }
   ],
   "source": [
    "from pypesq import pesq\n",
    "from scipy.io import wavfile\n",
    "\n",
    "rate, ref_audio = wavfile.read(r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\data\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac')\n",
    "rate, gen_audio_model1 = wavfile.read(r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac')\n",
    "rate, gen_audio_model2 = wavfile.read(r'C:\\CodeProjects\\University\\3.2_VU\\deep learning\\gmmGroup\\audioResults\\VitsModel\\07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.flac')\n",
    "\n",
    "pesq_score_model1 = pesq(rate, ref_audio, gen_audio_model1, 'wb')\n",
    "pesq_score_model2 = pesq(rate, ref_audio, gen_audio_model2, 'wb')\n",
    "\n",
    "print(f\"PESQ Score Model 1: {pesq_score_model1}\")\n",
    "print(f\"PESQ Score Model 2: {pesq_score_model2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
