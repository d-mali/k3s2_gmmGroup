import torch
from transformers import VitsModel, AutoTokenizer
tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')
tacotron2 = tacotron2.to('cuda')
tacotron2.eval()

waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')
waveglow = waveglow.remove_weightnorm(waveglow)
waveglow = waveglow.to('cuda')
waveglow.eval()

utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')


vitsModel = VitsModel.from_pretrained("facebook/mms-tts-eng")
vitsModel = vitsModel.to('cuda')
waveglow.eval()

tokenizer = AutoTokenizer.from_pretrained("facebook/mms-tts-eng")


def TTSTacotron2(text):
    sequences, lengths = utils.prepare_input_sequence([text])
    
    with torch.no_grad():
        mel, _, _ = tacotron2.infer(sequences, lengths)
        audio = waveglow.infer(mel)
    audio_numpy = audio[0].data.cpu().numpy()
    rate = 22050
    
    return audio_numpy, rate
    


def TTSVitsModel(text):
    inputs = tokenizer(text, return_tensors="pt").to('cuda')
    
    with torch.no_grad():
        output = vitsModel(**inputs).waveform
    output_waveform = output.squeeze().cpu().numpy()
    rate = 16000
    
    return output_waveform, rate


text = "Hello world, I missed you so much."


from IPython.display import Audio
print("Tacotron2")
audio_numpy, rate = TTSTacotron2(text)
Audio(audio_numpy, rate=rate)



from IPython.display import Audio
print("VitsModel")
audio_numpy, rate = TTSVitsModel(text)
Audio(audio_numpy, rate=rate)
